---
title: "Lab 5 Solutions"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
earthquake <- read.csv("https://sta279-s22.github.io/labs/EarthquakeData.csv")
```

### Question 1 (3 pts)

```{r message=F, warning=F}
earthquake %>%
  ggplot(aes(x = area_percentage)) +
  geom_histogram() +
  labs(x = "Area Percentage") +
  theme_bw()
```

```{r}
earthquake %>%
  summarize(median_area = median(area_percentage),
            iqr_area = IQR(area_percentage))
```

The distribution of area percentage is unimodal strongly right skewed, with almost all buildings having an area percentage less than 25, but the right tail extending to 100. The median area percentage is 7 and the IQR is 4.

**Grading:** 1 pt for plot, 1 pt for summary statistics, 1 pt for description

* If they use mean and standard deviation, don't take off points, but make a note that median and IQR are better for really skewed distributions.


### Question 2 (3 pts)

```{r echo=F}
log_rr_plot <- function(data, num_bins, bin_method,
                         x, y, cat_num, cat_denom,
                         grouping = NULL, reg_formula = y ~ x){
  
  if(is.null(grouping)){
    dat <- data.frame(x = data[,x], 
                      y = data[,y],
                      group = 1)
  } else {
    dat <- data.frame(x = data[,x], 
                      y = data[,y],
                      group = data[,grouping])
  }
  
  
  ##### Part to edit #####
  
  dat <- dat %>%
    filter(y %in% c(cat_num, cat_denom)) %>%
    mutate(obs = ifelse(y == cat_num, 1, 0))
  
  
  ########################
  
  
  if(bin_method == "equal_size"){
    logodds_table <- dat %>%
      slice_sample(n = nrow(dat), replace=F) %>%
      drop_na() %>%
      arrange(group, x) %>%
      group_by(group) %>%
      mutate(bin = rep(1:num_bins,
                       each=ceiling(n()/num_bins))[1:n()]) %>%
      group_by(bin, group) %>%
      summarize(mean_x = mean(x),
                prop = mean(c(obs, 0.5)),
                num_obs = n()) %>%
      ungroup() %>%
      mutate(logodds = log(prop/(1 - prop)))
  } else {
    logodds_table <- dat %>%
      slice_sample(n = nrow(dat), replace=F) %>%
      drop_na() %>%
      group_by(group) %>%
      mutate(bin = cut(x, 
                       breaks = num_bins,
                       labels = F)) %>%
      group_by(bin, group) %>%
      summarize(mean_x = mean(x),
                prop = mean(c(obs, 0.5)),
                num_obs = n()) %>%
      ungroup() %>%
      mutate(logodds = log(prop/(1 - prop)))
  }
  
  if(is.null(grouping)){
    logodds_table %>%
      ggplot(aes(x = mean_x,
                 y = logodds)) +
      geom_point(size=2.5) +
      geom_smooth(se=F, method="lm", formula = reg_formula) +
      theme_bw() +
      labs(x = x,
           y = paste("Log RR", cat_num, "vs.", cat_denom)) +
      theme(text = element_text(size=25))
  } else {
    logodds_table %>%
      ggplot(aes(x = mean_x,
                 y = logodds,
                 color = group,
                 shape = group)) +
      geom_point(size=2.5) +
      geom_smooth(se=F, method="lm", formula = reg_formula) +
      theme_bw() +
      labs(x = x,
           y = paste("Log RR", cat_num, "vs.", cat_denom),
           color = grouping,
           shape = grouping) +
      theme(text = element_text(size=25))
  }
  
}
```

```{r message=F, warning=F}
log_rr_plot(earthquake, 20, "equal_size", "area_percentage", "Damage", "none", "moderate")
```

The x-axis is only between 0 and 25, whereas the range of area in the data is between 0 and 100. This is a problem, because we don't know what the shape of the relationship might look like for area between 25 and 100.

**Grading:** 1 pt for plot, 2 pts for explanation


### Question 3 (2 pts)

The issue is the skewness of the distribution. Suppose we use 20 bins of equal size. The final bin, which contains the last 5% of the data, has to be a lot wider than the first bin.


### Question 4 (2 pts)

```{r message=F, warning=F}
log_rr_plot(earthquake, 20, "equal_width", "area_percentage", "Damage", "none", "moderate")
```

With bins of equal width, we now see the full range of area percentage. However, we see less detail for small areas, which is where most of the data is

**Grading:** 1 pt for plot, 1 pt for explanation

### Question 5 (2 pts)

```{r echo=F}
log_rr_table <- function(data, num_bins, bin_method,
                             x, y, cat_num, cat_denom,
                             grouping = NULL){
  if(is.null(grouping)){
    dat <- data.frame(x = data[,x], 
                      y = data[,y],
                      group = 1)
  } else {
    dat <- data.frame(x = data[,x], 
                      y = data[,y],
                      group = data[,grouping])
  }
  
  
  dat <- dat %>%
    filter(y %in% c(cat_num, cat_denom)) %>%
    mutate(obs = ifelse(y == cat_num, 1, 0))
  
  
  if(bin_method == "equal_size"){
    logodds_table <- dat %>%
      slice_sample(n = nrow(dat), replace=F) %>%
      drop_na() %>%
      arrange(group, x) %>%
      group_by(group) %>%
      mutate(bin = rep(1:num_bins,
                       each=ceiling(n()/num_bins))[1:n()]) %>%
      group_by(bin, group) %>%
      summarize(mean_x = mean(x),
                prop = mean(c(obs, 0.5)),
                num_obs = n()) %>%
      ungroup() %>%
      mutate(logodds = log(prop/(1 - prop)))
  } else {
    logodds_table <- dat %>%
      slice_sample(n = nrow(dat), replace=F) %>%
      drop_na() %>%
      group_by(group) %>%
      mutate(bin = cut(x, 
                       breaks = num_bins,
                       labels = F)) %>%
      group_by(bin, group) %>%
      summarize(mean_x = mean(x),
                prop = mean(c(obs, 0.5)),
                num_obs = n()) %>%
      ungroup() %>%
      mutate(logodds = log(prop/(1 - prop)))
  }
  
  return(logodds_table)
}
```

```{r message=F, warning=F}
log_rr_table(earthquake, 20, "equal_width", "area_percentage", "Damage", "none", "moderate")
```

No, we only have 3-5 observations in several of the bins in the right tail.

**Grading:** 1 pt for table, 1 pt for comment on small bins


### Question 6 (4 pts)

```{r message=F, warning=F}
earthquake <- earthquake %>%
  mutate(sqrt_area = sqrt(area_percentage))

log_rr_plot(earthquake, 12, "equal_width", "sqrt_area", "Damage", "none", "moderate")

log_rr_plot(earthquake, 20, "equal_width", "sqrt_area", "Damage", "none", "moderate")

log_rr_plot(earthquake, 30, "equal_width", "sqrt_area", "Damage", "none", "moderate")
```

**Grading:** 1 pt for making the new column, 1 pt for each plot


### Question 7 (4 pts)

```{r}
log_rr_plot(earthquake, 12, "equal_width", "sqrt_area", "Damage", "none", "moderate", reg_formula = y ~ poly(x, 2))

log_rr_plot(earthquake, 12, "equal_width", "sqrt_area", "Damage", "none", "moderate", reg_formula = y ~ poly(x, 3))

log_rr_plot(earthquake, 12, "equal_width", "sqrt_area", "Damage", "none", "moderate", reg_formula = y ~ poly(x, 4))
```

The fourth-order polynomial might fit best, but it might also be overfit, because we don't have that many points on the plot.

**Grading:** 1 pt for each plot, 1 pt for explanation

* It is ok if they prefer a different order polynomial, as long as they explain their reasoning


### Question 8 (2 pts)

```{r}
log_rr_plot(earthquake, 12, "equal_width", "sqrt_area", "Damage", "severe", "moderate", reg_formula = y ~ poly(x, 2))
```

It is hard to tell which transformation looks best here. I might prefer the polynomial of order 2, just for simplicity.

**Grading:** 1 pt for a plot, 1 pt for explanation (they can use a different polynomial transformation, they just need to explain their reasoning)

### Question 9 (3 pts)

```{r message=F, warning=F}
library(nnet)

m1 <- multinom(Damage ~ poly(sqrt_area, 2), data = earthquake)
AIC(m1)

m2 <- multinom(Damage ~ poly(sqrt_area, 3), data = earthquake)
AIC(m2)

m3 <- multinom(Damage ~ poly(sqrt_area, 4), data = earthquake)
AIC(m3)
```

The model with the lowest AIC is the polynomial transformation of order 4. This agrees with the plot in question 7, though in question 8 I was worried about overfitting.

**Grading:** 1 pt for fitting models, 1 pt for choosing model with lowest AIC, 1 pt for comparing to plots (answers may vary for comparison with plots)

### Question 10 (4 pts)

```{r}
m3 <- multinom(Damage ~ poly(age, 2, raw=T) + poly(sqrt_area, 4, raw=T), 
               data = earthquake)
summary(m3)
```

$$\log \left( \dfrac{\widehat{\pi}_{i(none)}}{\widehat{\pi}_{i(moderate)}} \right) = 6.15 - 0.078 age_i + 0.00038 age_i^2 - 7.23 area_i^{1/2} + 2.55 area_i - 0.34 area_i^{3/2} + 0.015 area_i^2$$

$$\log \left( \dfrac{\widehat{\pi}_{i(severe)}}{\widehat{\pi}_{i(moderate)}} \right) = -0.90 + 0.012 age_i - 0.00009 age_i^2 + 1.15 area_i^{1/2} - 0.54 area_i + 0.085 area_i^{3/2} - 0.0043 area_i^2$$

**Grading:** 2 pts for each equation

* lost 1 pt for missing subscripts and/or hats

### Question 11 (2 pts)

The predicted probability of severe damage is 0.31

**Grading:** They can get partial credit (1 pt) if they get the wrong answer but show their work


### Question 12 (4 pts)

```{r}
table("predictions" = predict(m3), "actual" = earthquake$Damage)
```

Overall accuracy: (80117 + 2823 + 18936)/211774 = 0.481

For no damage: 2823/24945 = 0.113

For moderate damage: 80117/100000 = 0.801

For severe damage: 18936/86829 = 0.218

We do ok at predicting moderate damage, but we're pretty bad at predicting no damage or severe damage. However, we are doing a better job with no damage and severe damage than we did in Lab 4.

**Grading:** 1 pt for accuracy, 1 pt for accuracy in each group, and 1 pt for comparison to lab 4

### Question 13 (3 pts)

* If we randomly assigned buildings to each category, with a 1/3 chance for each, then the overall accuracy would be 1/3. We're doing better than this overall accuracy, but that is only because we're good at predicting moderate damage.
* If we assigned every building to the "moderate" group, then our overall accuracy would be 0.472. Our accuracy is only slightly higher, though we do a better job with the other groups than this guessing scheme.

**Grading:** 1 pt for accuracy of each guessing scheme, 1 pt for comparison

### Question 14 (4 pts)

Full model:

$$\log \left( \dfrac{\pi_{i(none)}}{\pi_{i(moderate)}} \right) = \beta_{0(none)} + \beta_{1(none)} age_i + \beta_{2(none)} age_i^2 + \beta_{3(none)} area_i^{1/2} + \beta_{4(none)} area_i + \beta_{5(none)} area_i^{3/2} + \beta_{6(none)} area_i^2$$

$$\log \left( \dfrac{\pi_{i(severe)}}{\pi_{i(moderate)}} \right) = \beta_{0(severe)} + \beta_{1(severe)} age_i + \beta_{2(severe)} age_i^2 + \beta_{3(severe)} area_i^{1/2} + \beta_{4(severe)} area_i + \beta_{5(severe)} area_i^{3/2} + \beta_{6(severe)} area_i^2$$

Reduced model:

$$\log \left( \dfrac{\pi_{i(none)}}{\pi_{i(moderate)}} \right) = \beta_{0(none)} + \beta_{1(none)} area_i^{1/2} + \beta_{2(none)} area_i + \beta_{3(none)} area_i^{3/2} + \beta_{4(none)} area_i^2$$

$$\log \left( \dfrac{\pi_{i(severe)}}{\pi_{i(moderate)}} \right) = \beta_{0(severe)} + \beta_{1(severe)} area_i^{1/2} + \beta_{2(severe)} area_i + \beta_{3(severe)} area_i^{3/2} + \beta_{4(severe)} area_i^2$$

**Grading:** 2 pts for full model, 2 pts for reduced model

* Lose 1 pt if missing subscripts

### Question 15 (4 pts)

```{r}
m_full <- multinom(Damage ~ poly(age, 2, raw=T) + poly(sqrt_area, 4, raw=T), 
               data = earthquake)
summary(m_full)

m_reduced <- multinom(Damage ~ poly(sqrt_area, 4, raw=T), 
               data = earthquake)
summary(m_reduced)
```

test statistic: 405807.3 - 391311.8 = 14495.5

degrees of freedom: 4 (2 parameters in each log relative risk equation)

p-value: approximately 0

So we have strong evidence for a relationship between building age and damage, after accounting for building size.

**Grading:** 1 pt for test statistic, 1 pt for df, 1 pt for p-value, 1 pt for conclusion
