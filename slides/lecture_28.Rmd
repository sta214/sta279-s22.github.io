---
title: Inference and Overdispersion 
output:
  xaringan::moon_reader:
    css: "lab-slides.css"
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: console
---

### Agenda

---

### Data

.large[
We are interested in analyzing the number of articles published by biochemistry PhD students. The data contains the following variables:

* `art`: articles published in last three years of Ph.D.
* `fem`: gender (recorded as male or female)
* `mar`: marital status (recorded as married or single)
* `kid5`: number of children under age six
* `phd`: prestige of Ph.D. program
* `ment`: articles published by their mentor in last three years

.question[
What is the relationship between PhD prestige and the number of articles published, after accounting for other factors?
]
]

---

### Model

.large[

$$Articles_i \sim Poisson(\lambda_i)$$
$$\log(\lambda_i) = \beta_0 + \beta_1 Female_i + \beta_2 Married_i + \beta_3 Kids_i + \\  \beta_4 Prestige_i + \beta_5 Mentor_i$$

.question[
Do I need an offset for this model?
]
]

--

.large[
No -- there isn't a rate that we are interested in (e.g., we are looking at the same time window for each student)
]

---

### Model

.large[
$$Articles_i \sim Poisson(\lambda_i)$$
$$\log(\lambda_i) = \beta_0 + \beta_1 Female_i + \beta_2 Married_i + \beta_3 Kids_i + \\  \beta_4 Prestige_i + \beta_5 Mentor_i$$

.question[
We are interested in the relationship between prestige and the number of articles published, after accounting for other factors. What confidence interval should we make?
]
]

--

.large[
A confidence interval for $\exp\{\beta_4\}$ (the change in number of articles published for a unit increase in prestige)
]

---

### Confidence interval

.large[
```{r, echo=F, message=F, warning=F, output.lines = 10:16}
library(tidyverse)
library(foreign)
library(knitr)
hook_output <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
   lines <- options$output.lines
   if (is.null(lines)) {
     return(hook_output(x, options))  # pass to default hook
   }
   x <- unlist(strsplit(x, "\n"))
   more <- "..."
   if (length(lines)==1) {        # first n lines
     if (length(x) > lines) {
       # truncate the output, but add ....
       x <- c(head(x, lines), more)
     }
   } else {
     x <- c(more, x[lines], more)
   }
   # paste these lines together
   x <- paste(c(x, ""), collapse = "\n")
   hook_output(x, options)
 })

articles <- read.dta("http://www.stata-press.com/data/lf2/couart2.dta")

m1 <- glm(art ~ ., data = articles, family = poisson)
summary(m1)
```

.question[
How do I construct a confidence interval for $\exp\{\beta_4\}$?
]
]

---

### Confidence interval

.large[
```{r, echo=F, message=F, warning=F, output.lines = 10:16}
summary(m1)
```

95% confidence interval for $\beta_4$:

$0.0128 \pm 1.96 \cdot 0.0264 = (-0.0390, \ 0.0645)$

95% confidence interval for $\exp\{\beta_4\}$:

$(e^{-0.0390}, e^{0.0645}) = (0.962, \ 1.067)$
]

---

### Confidence interval

.large[
$$\log(\lambda_i) = \beta_0 + \beta_1 Female_i + \beta_2 Married_i + \beta_3 Kids_i + \\  \beta_4 Prestige_i + \beta_5 Mentor_i$$
95% confidence interval for $\exp\{\beta_4\}$:

$(e^{-0.0390}, e^{0.0645}) = (0.962, \ 1.067)$

.question[
How would we interpret this confidence interval?
]
]

--

.large[
We are 95% confident that a unit increase in program prestige is associated with an increase in the average number of articles published by a factor of between 0.962 and 1.067, holding other factors constant.
]

---

### Checking assumptions

.large[
* But, we haven't checked assumptions yet!
* Let's check the Poisson assumption
]

---

### Checking assumptions

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=7, fig.height=5}
articles %>%
  ggplot(aes(x = art)) +
  geom_bar() +
  theme_bw() +
  theme(text = element_text(size = 25)) +
  labs(x = "Number of articles published")
```

.large[
.question[
Does a Poisson distribution seem reasonable, given this plot?
]
]

---

### Checking assumptions

.large[
Checking the mean/variance condition:

```{r}
mean(articles$art)
var(articles$art)
```

.question[
Does it look like the mean and variance could be the same?
]
]

--

.large[
Maybe not -- the variance is more than twice the mean.
]

---

### Overdispersion

.large[
**Overdispersion** occurs when the response $Y$ has higher variance than we would expect if $Y$ followed a Poisson distribution.

.question[
What problems do you think it causes to assume the mean and variance are the same, when they are not?
]
]

--

.large[
Our estimates of the standard error are incorrect, which mean that our test statistics are larger than they should be, confidence intervals narrower, etc.
]

---

### Formal checks for overdispersion

.large[
First, we need a formal measure of dispersion (relation between mean and variance):

$$\phi = \dfrac{\text{Variance}}{\text{Mean}}$$

.question[
What should $\phi$ be if there is no overdispersion?
]
]

--

.large[
1
]

---

### Hypothesis test for overdispersion

.large[
$$\phi = \dfrac{\text{Variance}}{\text{Mean}}$$

$H_0: \phi = 1$ (no overdispersion)

$H_A: \phi > 1$ (overdispersion)

Now we need to estimate $\phi$...
]

---

### Pearson residuals and estimated dispersion

.large[
The *Pearson residual* for observation $i$ is defined as

$$e_{(P)i} = \dfrac{Y_i - \widehat{\lambda}_i}{\sqrt{\widehat{\lambda}_i}}$$

* Similar idea to standardized residuals in linear regression
* Tells us how far away the observed response $Y_i$ is from the estimated mean $\widehat{\lambda}_i$
]

--

.large[
$$\widehat{\phi} = \dfrac{\sum \limits_{i=1}^n e_{(P)i}^2}{n - p}$$

* $p =$ number of parameters in model
]

---

### Example: estimating dispersion parameter in R

.large[
```{r}
# fit the model
m1 <- glm(art ~ ., data = articles, 
          family = poisson)

# get Pearson residuals
pearson_resids <- resid(m1, "pearson")

# estimate dispersion parameter
phihat <- sum(pearson_resids^2)/(915 - 6)
phihat
```
]

---

### Back to the hypothesis test

.large[
$$\phi = \dfrac{\text{Variance}}{\text{Mean}}$$

$H_0: \phi = 1$ (no overdispersion)

$H_A: \phi > 1$ (overdispersion)

$\widehat{\phi} = 1.829$

.question[
Now what?
]
]

---

### Calculating a p-value

.large[

```{r, message=F, warning=F}
library(AER)
dispersiontest(m1)
```

So there is strong evidence for overdispersion in the data.
]

---

### Handling overdispersion

.large[
Overdispersion is a problem because our standard errors (for confidence intervals and hypothesis tests) are too low.

.question[
If we think there is overdispersion, what should we do?
]
]

--

.large[
* Option 1: Use $\widehat{\phi}$ to adjust tests and confidence intervals
* Option 2: Use a different distribution for the response
]

---

### Adjusting the standard error

.large[
* In our data, $\widehat{\phi} = 1.829$
* This means our variance is 1.829 times bigger than it should be
* So our standard error is $\sqrt{1.829} = 1.352$ times bigger than it should be

New confidence interval for $\beta_4$:

$0.0128 \pm 1.96 \cdot \sqrt{1.829} \cdot 0.0264 = (-0.0572, \ 0.0828)$
]

---

### Adjusting the standard error in R

.large[
```{r, message=F, warning=F}
m2 <- glm(art ~ ., data = articles, 
          family = quasipoisson)
```
]

```{r echo=F, output.lines = 10:20}
summary(m2)
```

.large[
* Allowing $\phi$ to be different from 1 means we are using a *quasi-likelihood* (in this case, a *quasi-Poisson*)
]

---

### Adjusting the standard error in R

.large[
**Poisson:**

```{r echo=F, output.lines = 10:14}
summary(m1)
```

**Quasi-Poisson:**

```{r echo=F, output.lines = 10:14}
summary(m2)
```
]

---

### Class activity

