<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Poisson Regression</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs-2.10/header-attrs.js"></script>
    <link rel="stylesheet" href="lab-slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Poisson Regression

---


### Agenda

---

### Data

.large[
A concerned parent asks us to investigate crime rates on college campuses. We have access to data on 81 different colleges and universities in the US, including the following variables:

* `type`: college (C) or university (U)
* `nv`: the number of violent crimes for that institution in the given year
* `enroll1000`: the number of enrolled students, in thousands
* `region`: region of the US C = Central, MW = Midwest, NE = Northeast, SE = Southeast, SW = Southwest, and W = West)
]

---

### Data

.large[
We want to know whether there are regional differences in the number of violent crimes on college campuses.

.question[
What would be a reasonable model to investigate this question?
]
]

--

.large[
`\(Crimes_i \sim Poisson(\lambda_i)\)`

`\(\log(\lambda_i) = \beta_0 + \beta_1 MW_i + \beta_2 NE_i + \beta_3 SE_i + \beta_4 SW_i + \beta_5 W_i\)`
]

---

### Model

.large[
`$$Crimes_i \sim Poisson(\lambda_i)$$`

`$$\log(\lambda_i) = \beta_0 + \beta_1 MW_i + \beta_2 NE_i + \beta_3 SE_i + \beta_4 SW_i + \beta_5 W_i$$`

.question[
What assumptions is this model making?
]
]

--

.large[
* Poisson distribution
* Independence
* Not making a shape assumption, because I just have a categorical predictor (so no notion of linearity)

.question[
How do I assess these assumptions?
]
]

---

### Checking assumptions

.large[
`$$Crimes_i \sim Poisson(\lambda_i)$$`

`$$\log(\lambda_i) = \beta_0 + \beta_1 MW_i + \beta_2 NE_i + \beta_3 SE_i + \beta_4 SW_i + \beta_5 W_i$$`

* Poisson assumption:
  * Check that response is a count
  * Check that the distribution of the response looks like it could be Poisson
  * Check that the mean and variance of the response are similar
* Independence: think about data
]

---

### Class activity, Part I

---

### Class activity

.large[
`$$\log(\widehat{\lambda}_i) = 1.34 + 0.48 \ MW_i + 0.44 \ NE_i + 0.77 \ SE_i + \\ 0.33 \ SW_i + 0.53 \ W_i$$`

.question[
How do I interpret the estimated intercept 1.34?
]
]

--

.large[
The estimated average number of crimes in a college in the central region is `\(\exp\{1.34\} = 3.82\)`.
]

---

### Class activity

.large[
`$$\log(\widehat{\lambda}_i) = 1.34 + 0.48 \ MW_i + 0.44 \ NE_i + 0.77 \ SE_i + \\ 0.33 \ SW_i + 0.53 \ W_i$$`

.question[
How do I interpret the estimated coefficient 0.48?
]
]

--

.large[
The average number of crimes in a college in the midwest region is `\(\exp\{0.48\} = 1.62\)` times higher than in the central region.
]

---

### Class activity

.large[
&lt;img src="lecture_27_files/figure-html/unnamed-chunk-1-1.png" style="display: block; margin: auto;" /&gt;

.question[
Does it look reasonable to assume a Poisson distribution for the response?
]
]

--

.large[
It does look like it might be reasonable, since the number of crimes is a count variable and has a unimodal, right skewed distribution.
]

---

### Class activity

.large[

```r
mean(crimes$nv)
```

```
## [1] 5.938272
```

```r
var(crimes$nv)
```

```
## [1] 54.83364
```

.question[
Does the Poisson distribution still seem reasonable?
]
]

--

.large[
Not necessarily -- the mean is much lower than the variance. We will see a couple options for handling this issue later.
]

---

### Goodness of fit

.large[
Another way to assess whether our model is reasonable is with a *goodness of fit* test.

**Goodness of fit test:** If the model is a good fit for the data, then the residual deviance follows a `\(\chi^2\)` distribution with the same degrees of freedom as the residual deviance


```
...
##     Null deviance: 649.34  on 80  degrees of freedom
## Residual deviance: 621.24  on 75  degrees of freedom
...
```

Residual deviance = 621.24, df = 75

.question[
How likely is a residual deviance of 621.24 if our model is correct?
]
]

---

### Goodness of fit

.large[
**Goodness of fit test:** If the model is a good fit for the data, then the residual deviance follows a `\(\chi^2\)` distribution with the same degrees of freedom as the residual deviance

Residual deviance = 621.24, df = 75


```r
pchisq(621.24, df=75, lower.tail=F)
```

```
## [1] 5.844298e-87
```

So our model might not be a very good fit to the data.

.question[
Why might our model not be a good fit?
]
]

---

### Potential issues with our model

.large[
* The Poisson distribution might not be a good choice
* There may be additional factors related to the number of violent crimes which we are not including in the model

.question[
Which other factors might be related to the number of violent crimes?
]
]

--

.large[
The number of students at the school!

* More students means more opportunities for crimes
]

---

### Offsets

.large[
We will account for school size by including an **offset** in the model:

`$$\log(\lambda_i) = \beta_0 + \beta_1 MW_i + \beta_2 NE_i + \beta_3 SE_i + \beta_4 SW_i + \beta_5 W_i \\ + \log(Enrollment_i)$$`

* `\(\log(Enrollment_i)\)` is an *offset*
* Notice the offset doesn't have a `\(\beta\)` term
* We are not trying to estimate a relationship between enrollment and the number of crimes; rather, we are just trying to adjust for the school size
]

---

### Motivation for offsets

.large[
We can rewrite our regression model with the offset:

`$$\log(\lambda_i) = \beta_0 + \beta_1 MW_i + \beta_2 NE_i + \beta_3 SE_i + \beta_4 SW_i + \beta_5 W_i \\ + \log(Enrollment_i)$$`

`$$\log(\lambda_i) - \log(Enrollment_i) = \beta_0 + \beta_1 MW_i + \beta_2 NE_i + \beta_3 SE_i \\ \hspace{3cm} + \beta_4 SW_i + \beta_5 W_i$$`

`$$\log \left( \dfrac{\lambda_i}{Enrollment_i} \right) = \beta_0 + \beta_1 MW_i + \beta_2 NE_i + \beta_3 SE_i \\ \hspace{3cm} + \beta_4 SW_i + \beta_5 W_i$$`

.question[
This means the `\(\beta\)`s can be interpreted in terms of *rates* (the rate of crime per 1000 students), rather than raw counts
]
]

---

### Fitting a model with an offset

.large[

```r
m2 &lt;- glm(nv ~ region, offset = log(enroll1000),
          data = crimes, family = poisson)
summary(m2)
```

```
...
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -1.30445    0.12403 -10.517  &lt; 2e-16 ***
## regionMW     0.09754    0.17752   0.549  0.58270    
## regionNE     0.76268    0.15292   4.987 6.12e-07 ***
## regionSE     0.87237    0.15313   5.697 1.22e-08 ***
## regionSW     0.50708    0.18507   2.740  0.00615 ** 
## regionW      0.20934    0.18605   1.125  0.26053    
...
```

* The offset doesn't show up in the output (because we're not estimating a coefficient for it)
]

---

### Fitting a model with an offset

.large[
`$$\log(\widehat{\lambda}_i) = -1.30 + 0.10 MW_i + 0.76 NE_i + \\ 0.87 SE_i + 0.51 SW_i + 0.21 W_i \\  + \log(Enrollment_i)$$`

.question[
How would I interpret the intercept -1.30?
]
]

--

.large[
The estimated crime rate (crimes per 1000 students) in central region schools is `\(\exp\{-1.30\} = 0.27\)`

.question[
What about the coefficient 0.1?
]
]

--

.large[
The estimated crime rate is `\(\exp\{0.1\} = 1.105\)` times higher for midwestern schools than for central schools
]

---

### When to use offsets

.large[
Offsets are useful in Poisson regression when our counts come from groups of very different sizes (e.g., different numbers of students on a college campus). The offset lets us interpret model coefficients in terms of rates instead of raw counts.

.question[
Brainstorm some other data scenarios where our response is a count variable, and an offset would be useful. What would our offset be?
]
]

--

.large[
* Example: We're interested in the number of births in US cities, but cities have very different populations. Offset: city population
* Example: We're interested in the number of tree species in US forests, but forests have very different sizes. Offset: area of forest
]

---

### Inference

.large[
`$$\log(\lambda_i) = \beta_0 + \beta_1 MW_i + \beta_2 NE_i + \beta_3 SE_i + \beta_4 SW_i + \beta_5 W_i \\ + \log(Enrollment_i)$$`

Our concerned parent wants to know whether the crime rate on campuses is different in different regions. 

.question[
What hypotheses would we test to answer this question?
]
]

--

.large[
`\(H_0: \beta_1 = \beta_2 = \beta_3 = \beta_4 = \beta_5 = 0\)`

`\(H_A: \text{at least one of } \beta_1,...,\beta_5 \neq 0\)`

.question[
What test can we use?
]
]

---

### Likelihood ratio test

.large[
Full model:

`$$\log(\lambda_i) = \beta_0 + \beta_1 MW_i + \beta_2 NE_i + \beta_3 SE_i + \beta_4 SW_i + \beta_5 W_i \\ + \log(Enrollment_i)$$`

Reduced model:

`$$\log(\lambda_i) = \beta_0 + \log(Enrollment_i)$$`
]

---

### Likelihood ratio test

.large[

```r
m2 &lt;- glm(nv ~ region, offset = log(enroll1000),
          data = crimes, family = poisson)
summary(m2)
```

```
...
##     Null deviance: 491.00  on 80  degrees of freedom
## Residual deviance: 433.14  on 75  degrees of freedom
...
```

.question[
What is my test statistic?
]
]

--

.large[
`\(G = 491 - 433.14 = 57.86\)`

.question[
How do I calculate a p-value?
]
]

---

### Likelihood ratio test

.large[

```r
m2 &lt;- glm(nv ~ region, offset = log(enroll1000),
          data = crimes, family = poisson)
summary(m2)
```

```
...
##     Null deviance: 491.00  on 80  degrees of freedom
## Residual deviance: 433.14  on 75  degrees of freedom
...
```

`\(G = 491 - 433.14 = 57.86\)`


```r
pchisq(57.86, df=5, lower.tail=F)
```

```
## [1] 3.361742e-11
```
]

---

### Confidence interval

.large[
`$$\log(\lambda_i) = \beta_0 + \beta_1 MW_i + \beta_2 NE_i + \beta_3 SE_i + \beta_4 SW_i + \beta_5 W_i \\ + \log(Enrollment_i)$$`

Now our concerned parent is specifically interested in comparing crime rates between central and western schools. What confidence interval should we make?
]

--

.large[
A confidence interval for `\(\exp\{\beta_5\}\)` (the change in crime rates between central and western schools)
]

---

### Confidence interval

.large[

```
...
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -1.30445    0.12403 -10.517  &lt; 2e-16 ***
## regionMW     0.09754    0.17752   0.549  0.58270    
## regionNE     0.76268    0.15292   4.987 6.12e-07 ***
## regionSE     0.87237    0.15313   5.697 1.22e-08 ***
## regionSW     0.50708    0.18507   2.740  0.00615 ** 
## regionW      0.20934    0.18605   1.125  0.26053    
...
```

95% confidence interval for `\(\beta_5\)`:

`\(0.21 \pm 1.96 \cdot 0.186 = (-0.155, \ 0.575)\)`

95% confidence interval for `\(\exp\{\beta_5\}\)`:

`\((e^{-0.155}, e^{0.575}) = (0.856, \ 1.777)\)`
]

---

### Confidence interval

.large[
`$$\log(\lambda_i) = \beta_0 + \beta_1 MW_i + \beta_2 NE_i + \beta_3 SE_i + \beta_4 SW_i + \beta_5 W_i \\ + \log(Enrollment_i)$$`

95% confidence interval for `\(\exp\{\beta_5\}\)`:

`\((e^{-0.155}, e^{0.575}) = (0.856, \ 1.777)\)`

.question[
How would we interpret this confidence interval?
]
]

--

.large[
We are 95% confident that the crime rate for schools in the western region is between 0.856 and 1.777 times higher than for schools in the central region.
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
